#!/bin/bash
echo "============================================"
echo "   VERIFICA√á√ÉO FINAL DO SISTEMA AI_CORE"
echo "============================================"
echo ""
echo "‚úÖ CONFIGURA√á√ÉO ATUAL:"
echo "  ‚Ä¢ Mem√≥ria: 8GB (realista)"
echo "  ‚Ä¢ Batch: 128 registros"  
echo "  ‚Ä¢ Cores: 4"
echo "  ‚Ä¢ API: Removida"
echo "  ‚Ä¢ Airflow: Script pronto"
echo ""
echo "üìÇ ARQUIVOS IMPORTANTES:"
echo -n "  ‚Ä¢ run_for_airflow.py: "
[[ -f /home/lgsilva/SAT_IA/ai_core/run_for_airflow.py ]] && echo "‚úÖ" || echo "‚ùå"

echo -n "  ‚Ä¢ submit_treino.sh (8GB): "
grep -q "8g" /home/lgsilva/SAT_IA_API/aicore-gpu/scripts/submit_treino.sh 2>/dev/null && echo "‚úÖ" || echo "‚ùå"

echo -n "  ‚Ä¢ global_config.py: "
[[ -f /home/lgsilva/SAT_IA/ai_core/src/ai_toolkit/config/global_config.py ]] && echo "‚úÖ" || echo "‚ùå"

echo ""
echo "üöÄ COMANDOS PARA PRODU√á√ÉO:"
echo ""
echo "1. TREINAR MODELO:"
echo "   cd /home/lgsilva/SAT_IA_API/aicore-gpu/scripts"
echo "   ./submit_treino.sh -i hdfs:///data/train.csv -o hdfs:///models/v2 -m modelo_v2"
echo ""
echo "2. PREDI√á√ÉO BATCH:"
echo "   ./submit_predicao.sh -i hdfs:///data/batch.csv -o hdfs:///output/pred.csv -m modelo_v2"
echo ""
echo "3. USO NO AIRFLOW:"
echo "   from airflow import DAG"
echo "   from airflow.operators.bash import BashOperator"
echo "   "
echo "   predict = BashOperator("
echo "       task_id='predict',"
echo "       bash_command='cd /home/lgsilva/SAT_IA/ai_core && python3 run_for_airflow.py input.csv output.csv'"
echo "   )"
echo ""
echo "============================================"
echo "‚úÖ SISTEMA PRONTO PARA PRODU√á√ÉO!"
echo "============================================"
